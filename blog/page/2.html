<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="generator" content="Hugo 0.81.0" />


  <title>Blog - DeclareDesign</title>




  





<link href="/blog/index.xml" rel="alternate" type="application/rss+xml" title="A Hugo website" />





<link rel='stylesheet' href='https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css'>



<script defer src="https://use.fontawesome.com/releases/v5.5.0/js/all.js" integrity="sha384-GqVMZRt5Gn7tB9D9q7ONtcp4gtHIUEW/yG7h98J7IpE3kpi+srfFyyB/04OV6pG0" crossorigin="anonymous"></script>

<link href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,500,500i,700,700i" rel="stylesheet">

<link rel="stylesheet" href="/css/bootstrap.min.css">

<script src="https://code.jquery.com/jquery-3.3.1.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script>






  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Blog">
  <meta name="twitter:description" content='
'>






<script src="/js/dropdown_menu.js"></script>
<link rel="stylesheet" href="/css/custom.css">

  </head>
  <body>
    <div class="wrapper">
      
        
<header>
  <div class="navbar-wrap fixed-top bg-white">
    <nav class="navbar navbar-expand-lg navbar-light">
      <div class="container-fluid"> <a class="navbar-brand" href="/"><img src="/images/brand.svg" alt=""></a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"> <span class="navbar-toggler-icon"></span> </button>
        <div class="collapse navbar-collapse" id="navbarSupportedContent">
          <ul class="navbar-nav ml-auto">
            <li class="nav-item"><a class="nav-link" href="/getting-started.html">Getting Started</a></li>
            <li class="nav-item"><a class="nav-link" href="/r/designlibrary">Library</a></li>
            <li class="nav-item dropdown">
              
              <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown">Software <b class="caret"></b></a>
              <ul class="dropdown-menu">
                <li><a class="dropdown-item" href="/r/declaredesign/">DeclareDesign</a></li>
                <li><a class="dropdown-item" href="/r/randomizr/">randomizr</a></li>
                <li><a class="dropdown-item" href="/r/fabricatr/">fabricatr</a></li>
                <li><a class="dropdown-item" href="/r/estimatr/">estimatr</a></li>
                <li><a class="dropdown-item" href="/r/designlibrary/">DesignLibrary</a></li>
              </ul>
            </li>
            <li class="nav-item"><a class="nav-link" href="/blog.html">Blog</a></li>
            <li class="nav-item"><a class="nav-link" href="/about.html">About</a></li>
            <li class="nav-item"><a target="_blank" class="nav-link" href="http://discuss.declaredesign.org/">Help</a></li>
          </ul>
        </div>
      </div>
    </nav>
  </div>
</header>

 

      


<main class="container">

  
  <div class="archive">
    <a class="h1 d-block mb-3" href="/blog">DeclareDesign Blog</a>
    
      <article class="archive-item">
        <a href="/blog/meta-analysis-can-be-used-not-just-to-guess-about-effects-out-of-sample-but-also-to-re-evaluate-effects-in-sample.html" class="archive-item-link">Meta-analysis can be used not just to guess about effects out-of-sample but also to re-evaluate effects in sample</a>
        <span class="archive-item-date">
          2018/12/11
        </span>
        
          
        
        <div class="blog_summary"><p>Imagine you are in the fortunate position of planning a collection of studies which you will later get to analyze together (looking at you <a href="https://egap.org/metaketa">metaketas</a>). Each study estimates a site specific effect. You want to learn something about general effects. We work through design issues using a multi-study design with <code>J</code> studies that employs both frequentist and Bayesian approaches to meta-analysis. In the designs that we diagnose these perform very similarly in terms of estimating sample and population average effects. But there are tradeoffs. The Bayesian model does better at estimating individual effects by separating out true heterogeneity from sampling error but can sometimes fare poorly at estimating prediction intervals.</p></div>
        
          <div><a href="/blog/meta-analysis-can-be-used-not-just-to-guess-about-effects-out-of-sample-but-also-to-re-evaluate-effects-in-sample.html">Read More…</a></div>
        
      </article>
      <hr/>
    
      <article class="archive-item">
        <a href="/blog/get-me-a-random-assignment-yesterday.html" class="archive-item-link">Get me a random assignment YESTERDAY</a>
        <span class="archive-item-date">
          2018/12/04
        </span>
        
          
        
        <div class="blog_summary"><p>You’re partnering with an education nonprofit and you are planning on running a randomized control trial in 80 classrooms spread across 20 community schools. The request is in: please send us a spreadsheet with random assignments. The assignment’s gotta be blocked by school, it’s gotta be reproducible, and it’s gotta be tonight. The good news is that you can do all this in a couple of lines of code. We show how using some DeclareDesign tools and then walk through handling of more complex cases.</p></div>
        
          <div><a href="/blog/get-me-a-random-assignment-yesterday.html">Read More…</a></div>
        
      </article>
      <hr/>
    
      <article class="archive-item">
        <a href="/blog/randomization-does-not-justify-t-tests.-how-worried-should-i-be.html" class="archive-item-link">Randomization does not justify t-tests. How worried should I be?</a>
        <span class="archive-item-date">
          2018/11/27
        </span>
        
          
        
        <div class="blog_summary"><p><span class="citation">Deaton and Cartwright (<a href="#ref-deaton2017understanding" role="doc-biblioref">2017</a>)</span> provide multiple arguments against claims that randomized trials should be thought of as a kind of gold standard of scientific evidence. One striking argument they make is that randomization does not justify the statistical tests that researchers typically use. They are right in that. Even if researchers can claim that their estimates of uncertainty are justified by randomization, their habitual use of those estimates to conduct <em>t</em>-tests are not. To get a handle on how severe the problem is we replicate the results in <span class="citation">Deaton and Cartwright (<a href="#ref-deaton2017understanding" role="doc-biblioref">2017</a>)</span> and then use a wider set of diagnosands to probe more deeply. Our investigation suggests that what at first seems like a big problem might not in fact be so great if your hypotheses are what they often are for experimentalists—sharp and sample-focused.</p></div>
        
          <div><a href="/blog/randomization-does-not-justify-t-tests.-how-worried-should-i-be.html">Read More…</a></div>
        
      </article>
      <hr/>
    
      <article class="archive-item">
        <a href="/blog/modelling_spillovers.html" class="archive-item-link">Instead of avoiding spillovers, you can model them</a>
        <span class="archive-item-date">
          2018/11/20
        </span>
        
          
        
        <div class="blog_summary"><p>Spillovers are often seen as a nuisance that lead researchers into error when estimating effects of interest. In a <a href="https://declaredesign.org/blog/2018-09-18-spillovers.html">previous post,</a> we discussed sampling strategies to reduce these risks. A more substantively satisfying approach is to try to study spillovers directly. If we do it right we can remove errors in our estimation of primary quantities of interest and learn about how spillovers work at the same time.</p></div>
        
          <div><a href="/blog/modelling_spillovers.html">Read More…</a></div>
        
      </article>
      <hr/>
    
      <article class="archive-item">
        <a href="/blog/2018-11-13-learning-from-p.html" class="archive-item-link">What does a p-value tell you about the probability a hypothesis is true?</a>
        <span class="archive-item-date">
          2018/11/13
        </span>
        
          
        
        <div class="blog_summary"><p>The humble <span class="math inline">\(p\)</span>-value is much maligned and terribly misunderstood. The problem is that everyone wants to know the answer to the question: “what is the probability that [hypothesis] is true?” But <span class="math inline">\(p\)</span> answers a different (and not terribly useful) question: “how (un)surprising is this evidence given [hypothesis]?” Can <span class="math inline">\(p\)</span> shed insight on the question we really care about? Maybe, though there are dangers.</p></div>
        
          <div><a href="/blog/2018-11-13-learning-from-p.html">Read More…</a></div>
        
      </article>
      <hr/>
    
      <article class="archive-item">
        <a href="/blog/neyman-sate-pate.html" class="archive-item-link">Common estimators of uncertainty overestimate uncertainty</a>
        <span class="archive-item-date">
          2018/11/07
        </span>
        
          
        
        <div class="blog_summary"><p>Random assignment provides a justification not just for estimates of effects but also for estimates of uncertainty about effects. The basic approach, due to Neyman, is to estimate the variance in estimates of the difference between outcomes in treatment and in control outcomes using the variability that can be observed among units in control and units in treatment. It’s an ingenious approach and dispenses with the need to make any assumptions about the shape of statistical distributions or about asymptotics. The problem though is that it can sometimes be <strong>upwardly biased</strong>, meaning that it might lead you to maintain null hypotheses when you should be rejecting them. We use design diagnosis to get a handle on how great this problem is and how it matters for different estimands.</p></div>
        
          <div><a href="/blog/neyman-sate-pate.html">Read More…</a></div>
        
      </article>
      <hr/>
    
      <article class="archive-item">
        <a href="/blog/bias-cluster-randomized-trials.html" class="archive-item-link">Cluster randomized trials can be biased when cluster sizes are heterogeneous</a>
        <span class="archive-item-date">
          2018/10/31
        </span>
        
          
        
        <div class="blog_summary"><p>In many experiments, random assignment is performed at the level of clusters. Researchers are conscious that in such cases they cannot rely on the usual standard errors and they should take account of this feature by clustering their standard errors. Another, more subtle, risk in such designs is that if clusters are of different sizes, clustering can actually introduce bias, <em>even if all clusters are assigned to treatment with the same probability</em>. Luckily, there is a relatively simple fix that you can implement at the design stage.</p></div>
        
          <div><a href="/blog/bias-cluster-randomized-trials.html">Read More…</a></div>
        
      </article>
      <hr/>
    
      <article class="archive-item">
        <a href="/blog/with-great-power-comes-great-responsibility.html" class="archive-item-link">With great power comes great responsibility</a>
        <span class="archive-item-date">
          2018/10/23
        </span>
        
          
        
        <div class="blog_summary"><p>We usually think that the bigger the study the better. And so huge studies often rightly garner great publicity. But the ability to generate more precise results also comes with a risk. If study designs are at risk of bias and readers (or publicists!) employ a <a href="https://andrewgelman.com/2011/09/10/the-statistical-significance-filter/">statistical significance filter</a>, then big data might not remove threats of bias and might actually make things worse.</p></div>
        
          <div><a href="/blog/with-great-power-comes-great-responsibility.html">Read More…</a></div>
        
      </article>
      <hr/>
    
      <article class="archive-item">
        <a href="/blog/how-misleading-are-clustered-ses-in-designs-with-few-clusters.html" class="archive-item-link">How misleading are clustered SEs in designs with few clusters?</a>
        <span class="archive-item-date">
          2018/10/16
        </span>
        
          
        
        <div class="blog_summary"><p>Cluster-robust standard errors are known to behave badly with too few clusters. There is a great discussion of this issue by Berk Özler <a href="https://blogs.worldbank.org/impactevaluations/beware-of-studies-with-a-small-number-of-clusters">“Beware of studies with a small number of clusters”</a> drawing on studies by <span class="citation">Cameron, Gelbach, and Miller (<a href="#ref-cameron2008bootstrap" role="doc-biblioref">2008</a>)</span>. See also this nice post by <a href="http://cyrussamii.com/?p=1246">Cyrus Samii</a> and a recent treatment by <span class="citation">Esarey and Menger (<a href="#ref-esarey2018practical" role="doc-biblioref">2018</a>)</span>. A rule of thumb is to start worrying about sandwich estimators when the number of clusters goes below 40. But here we show that diagnosis of a canonical design suggests that some sandwich approaches fare quite well even with fewer than 10 clusters.</p></div>
        
          <div><a href="/blog/how-misleading-are-clustered-ses-in-designs-with-few-clusters.html">Read More…</a></div>
        
      </article>
      <hr/>
    
      <article class="archive-item">
        <a href="/blog/biased-fixed-effects.html" class="archive-item-link">The trouble with &lsquo;controlling for blocks&rsquo;</a>
        <span class="archive-item-date">
          2018/10/09
        </span>
        
          
        
        <div class="blog_summary"><p>In many experiments, different groups of units get assigned to treatment with different probabilities. This can give rise to misleading results unless you properly take account of possible differences between the groups. How best to do this? The go-to approach is to “control” for groups by introducing “fixed-effects” in a regression set-up. The bad news is that this procedure is prone to bias. The good news is that there’s an even simpler and more intuitive approach that gets it right: estimate the difference-in-means within each group, then average over these group-level estimates weighting according to the size of the group. We’ll use design declaration to show the problem and to compare the performance of this and an array of other proposed solutions.</p></div>
        
          <div><a href="/blog/biased-fixed-effects.html">Read More…</a></div>
        
      </article>
      <hr/>
    
    

<ul class="pagination justify-content-center">
    
    <li class="page-item">
        <a href="/blog.html" class="page-link" aria-label="First"><span aria-hidden="true">&laquo;&laquo;</span></a>
    </li>
    
    <li class="page-item">
    <a href="/blog.html" class="page-link" aria-label="Previous"><span aria-hidden="true">&laquo;</span></a>
    </li>
    
    
    
    
    
    
        
        
    
    
    <li class="page-item"><a class="page-link" href="/blog.html">1</a></li>
    
    
    
    
    
    
        
        
    
    
    <li class="page-item active"><a class="page-link" href="/blog/page/2.html">2</a></li>
    
    
    
    
    
    
        
        
    
    
    <li class="page-item"><a class="page-link" href="/blog/page/3.html">3</a></li>
    
    
    <li class="page-item">
    <a href="/blog/page/3.html" class="page-link" aria-label="Next"><span aria-hidden="true">&raquo;</span></a>
    </li>
    
    <li class="page-item">
        <a href="/blog/page/3.html" class="page-link" aria-label="Last"><span aria-hidden="true">&raquo;&raquo;</span></a>
    </li>
    
</ul>


  </div>
  
</main>

    </div>

    

<footer>
    <div class="footer-top">
      <div class="container">
        <div class="row no-gutters">
          <div class="col-lg-7 col-md-12">
            <div class="row">
              <div class="col-md-3 col-12">
                <div class="footer-brand"><a href=""><img src="/images/brand-footer.svg" alt=""></a></div>
              </div>
              <div class="col-md-3 col-4">
                <p>DeclareDesign</p>
                <ul class="list-unstyled">
                  <li><a href="/">Home</a></li>
                  <li><a href="/about.html">About</a></li>
                  <li><a href="/r/designlibrary">Library</a></li>
                  <li><a href="/blog.html">Blog</a></li>
                  <li><a href="http://discuss.declaredesign.org/">Help</a></li>
                </ul>
              </div>
              <div class="col-md-3 col-4">
                <p>Software</p>
                <ul class="list-unstyled">
                  <li><a href="/r/declaredesign/">DeclareDesign</a></li>
                  <li><a href="/r/estimatr/">estimatr</a></li>
                  <li><a href="/r/randomizr/">randomizr</a></li>
                  <li><a href="/r/fabricatr/">fabricatr</a></li>
                  <li><a href="/r/designlibrary/">DesignLibrary</a></li>
                </ul>
              </div>
              
            </div>
          </div>
          <div class="col-lg-5 col-md-12"></div>
        </div>
      </div>
    </div>
    <div class="footer-bottom">
      <div class="footer-meta-block">
        <div class="container">
          <div class="row align-items-center">
            <div class="col-sm-7">
              <p class="mb-0">&copy; 2021 Graeme Blair, Jasper Cooper, Alexander Coppock, and Macartan Humphreys</p>
            </div>
            <div class="col-sm-5">
              <div class="fbl-link-wrap">
                <ul class="list-inline mb-0">
                  <li class="list-inline-item"> <a target="_blank" href="http://github.com/DeclareDesign/"><img src="images/icon-git.svg" alt=""></a> </li>
                </ul>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </footer>
  
   
  
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js" integrity="sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/js/bootstrap.min.js" integrity="sha384-ChfqqxuZUCnJSK3+MXmPNIyE6ZbWh2IMqE241rYiqJxyMiZ6OW/JmZQ5stwEULTy" crossorigin="anonymous"></script>

    <link rel="stylesheet" href="https://cdn.datatables.net/v/bs4/dt-1.10.18/datatables.min.css"/>
<script src="https://cdn.datatables.net/v/bs4/dt-1.10.18/datatables.min.js"></script>

<script>
    jQuery(function ()
    {
        const library_list = jQuery("#design_library_list");
        library_list.addClass("table table-striped table-bordered");
        library_list.DataTable(
            {
                "autoWidth": false,
                "columns":
                    [
                        {"width": "30%"}, 
                        {"width": "10%"}, 
                        {"width": "10%"}, 
                        {"width": "10%"}, 
                        {"width": "15%"}, 
                        {"width": "25%"}, 
                    ],
                "drawCallback": initialize_tooltips
            }
        );

        library_list.css("width", "");
    });

    function initialize_tooltips()
    {
        const tooltip_elements = jQuery('[data-toggle="tooltip"]');
        tooltip_elements.tooltip();
        tooltip_elements.click(function ()
        {
            jQuery(this).tooltip("hide");
        });
    }
</script>

    


<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>



<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/r.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/yaml.min.js"></script>
<script>
jQuery(function ()
{
  $('pre').each(function (index)
  {
    hljs.highlightBlock(this);
  });
});
</script>



    
<script src="/js/math-code.js"></script>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>


    



    
  </body>
</html>

