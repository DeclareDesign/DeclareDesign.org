<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="generator" content="Hugo 0.81.0" />


  <title>Meta-analysis can be used not just to guess about effects out-of-sample but also to re-evaluate effects in sample - DeclareDesign</title>




  









<link rel='stylesheet' href='https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css'>



<script defer src="https://use.fontawesome.com/releases/v5.5.0/js/all.js" integrity="sha384-GqVMZRt5Gn7tB9D9q7ONtcp4gtHIUEW/yG7h98J7IpE3kpi+srfFyyB/04OV6pG0" crossorigin="anonymous"></script>

<link href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,500,500i,700,700i" rel="stylesheet">

<link rel="stylesheet" href="/css/bootstrap.min.css">

<script src="https://code.jquery.com/jquery-3.3.1.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script>






  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Meta-analysis can be used not just to guess about effects out-of-sample but also to re-evaluate effects in sample">
  <meta name="twitter:description" content='Imagine you are in the fortunate position of planning a collection of studies which you will later get to analyze together (looking at you metaketas). Each study estimates a site specific effect. You want to learn something about general effects. We work through design issues using a multi-study design with J studies that employs both frequentist and Bayesian approaches to meta-analysis. In the designs that we diagnose these perform very similarly in terms of estimating sample and population average effects. But there are tradeoffs. The Bayesian model does better at estimating individual effects by separating out true heterogeneity from sampling error but can sometimes fare poorly at estimating prediction intervals.

'>






<script src="/js/dropdown_menu.js"></script>
<link rel="stylesheet" href="/css/custom.css">

  </head>
  <body>
    <div class="wrapper">
      
        
<header>
  <div class="navbar-wrap fixed-top bg-white">
    <nav class="navbar navbar-expand-lg navbar-light">
      <div class="container-fluid"> <a class="navbar-brand" href="/"><img src="/images/brand.svg" alt=""></a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"> <span class="navbar-toggler-icon"></span> </button>
        <div class="collapse navbar-collapse" id="navbarSupportedContent">
          <ul class="navbar-nav ml-auto">
            <li class="nav-item"><a class="nav-link" href="/getting-started.html">Getting Started</a></li>
            <li class="nav-item"><a class="nav-link" href="/r/designlibrary">Library</a></li>
            <li class="nav-item dropdown">
              
              <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown">Software <b class="caret"></b></a>
              <ul class="dropdown-menu">
                <li><a class="dropdown-item" href="/r/declaredesign/">DeclareDesign</a></li>
                <li><a class="dropdown-item" href="/r/randomizr/">randomizr</a></li>
                <li><a class="dropdown-item" href="/r/fabricatr/">fabricatr</a></li>
                <li><a class="dropdown-item" href="/r/estimatr/">estimatr</a></li>
                <li><a class="dropdown-item" href="/r/designlibrary/">DesignLibrary</a></li>
              </ul>
            </li>
            <li class="nav-item"><a class="nav-link" href="/blog.html">Blog</a></li>
            <li class="nav-item"><a class="nav-link" href="/about.html">About</a></li>
            <li class="nav-item"><a target="_blank" class="nav-link" href="http://discuss.declaredesign.org/">Help</a></li>
          </ul>
        </div>
      </div>
    </nav>
  </div>
</header>

 

      


<main class="container">
  <div class="row justify-content-between">
    <div class="col-lg-12" id="content_column">
      <article class="article">

        <a class="h1 d-block mb-3" href="/blog">DeclareDesign Blog</a>
        <h2 class="article-title">Meta-analysis can be used not just to guess about effects out-of-sample but also to re-evaluate effects in sample</h2>

        
        <span class="article-date">2018/12/11</span>
        

        <div class="article-content">
          


<p>Imagine you are in the fortunate position of planning a collection of studies which you will later get to analyze together (looking at you <a href="https://egap.org/metaketa">metaketas</a>). Each study estimates a site specific effect. You want to learn something about general effects. We work through design issues using a multi-study design with <code>J</code> studies that employs both frequentist and Bayesian approaches to meta-analysis. In the designs that we diagnose these perform very similarly in terms of estimating sample and population average effects. But there are tradeoffs. The Bayesian model does better at estimating individual effects by separating out true heterogeneity from sampling error but can sometimes fare poorly at estimating prediction intervals.</p>
<div id="what-questions-might-a-meta-analysis-try-to-answer" class="section level2">
<h2>What questions might a meta-analysis try to answer?</h2>
<p>We are interested in effects within individual studies, in some “general” effect, and in effect variability. We imagine a setting in which effects from <span class="math inline">\(J\)</span> studies are drawn from a population of possible cases with effects:
<span class="math display">\[\theta_i \sim f(\mu, \tau) \text{ for } i \in \{1,2,\dots, J\}\]</span>
We will assume that <span class="math inline">\(f\)</span> is Normal but we will be able to see what happens if we are wrong about that. <em>The most important assumption we make here is that the studies are random draws from a population.</em> In practice that is almost never the case, though that may change as researchers coordinate more on multi-site projects.</p>
<p>Actual estimates are given by:
<span class="math display">\[\hat{\theta}_i \sim N(\theta_i, \sigma_i) \text{ for } i \in \{1,2,\dots, J\}\]</span>
The idea here is that estimates are a draw from a Normal distribution centered on the truth, but with some sampling error. Thus we are assuming that whatever estimation strategy is used is unbiased. The size of the error will depend on things like the sample size and estimation strategy. We will assume it is the same for all studies (though that’s largely a design issue that you could experiment with as part of the declaration).</p>
<p><em>In summary, we are assuming a world where knowing the estimates from a case tell us something about the actual effects in that case and knowing something about the actual effects in a case tells us something about effects in a population of cases.</em></p>
<p>Our challenge is: given a set of estimates, <span class="math inline">\(\hat{\theta}\)</span>, and a set of estimates of sampling error, <span class="math inline">\(\hat{\sigma}\)</span>, can we figure out:</p>
<ul>
<li><span class="math inline">\(\mu\)</span> the population average effect</li>
<li><span class="math inline">\(\tau\)</span> the fundamental heterogeneity of effects</li>
<li><span class="math inline">\(\theta\)</span> the country level effects and <span class="math inline">\(\overline{\theta}\)</span> the average effect in our sample</li>
</ul>
<p>In addition, partially heeding <span class="citation">IntHout et al. (<a href="#ref-inthout2016plea" role="doc-biblioref">2016</a>)</span>’s plea for presenting “prediction intervals,” we will add an <em>estimate</em> for the probability that a new study will have a positive effect:</p>
<ul>
<li><span class="math inline">\(\int_{0}^{\infty}f(x|\mu, \sigma)dx\)</span></li>
</ul>
<p>Though not worked in here, you might be interested in still deeper questions such as trying to <em>explain</em> variation in effects across studies and using this variation to make predictions to new cases given information about those cases (this is the stuff of “meta-regression”) and could be done with a relatively modest modification of the design we declare below.</p>
</div>
<div id="a-meta-design" class="section level1">
<h1>A meta-design</h1>
<p>We imagine a design in which we generate a set of <span class="math inline">\(J\)</span> studies, each producing unbiased estimates of a study specific treatment effect as well as estimates of uncertainty.</p>
<p>We consider three approaches to estimating quantities of interest:</p>
<ol style="list-style-type: decimal">
<li>An agnostic frequentist approach that takes the study level effects at face value. We will also include a fairly naive approach to quantifying effect heterogeneity using the standard deviation of study effects (spoiler: this won’t do very well but we are including it in case you’d be tempted to reach for this).</li>
</ol>
<pre class="r"><code>f_agnostic = function(data) with(data,  {
  data.frame(estimate = c(muhat    = mean(est_effects),
                         tauhat    = sd(est_effects),
                         study_est = est_effects[1]))})</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>A model-based frequentist approach in which the estimates for <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\tau\)</span> are generated using a random effects model via maximum likelihood procedures using the <code>metaplus</code> package <span class="citation">(Beath and Bolker <a href="#ref-beath2015metaplus" role="doc-biblioref">2015</a>)</span>.</li>
</ol>
<pre class="r"><code>f_metaplus = function(data) with(data,  {
  metaplus_result &lt;- metaplus(yi = est_effects, sei = est_sds)
  metaplus_ests   &lt;- summary(metaplus_result)[[1]][1:2,1]
  data.frame(estimate = c(muhat    = metaplus_ests[1],
                          tauhat   = metaplus_ests[2]^.5,
                          prob_pos = 1-pnorm(0, metaplus_ests[1], metaplus_ests[2])))
})</code></pre>
<ol start="3" style="list-style-type: decimal">
<li>For a Bayesian approach we will use the “8 schools model” <span class="citation">(Gelman et al. <a href="#ref-gelman2013bayesian" role="doc-biblioref">2013</a>)</span> implemented via <a href="http://mc-stan.org/">stan</a>. See <a href="https://github.com/stan-dev/rstan/wiki/RStan-Getting-Started">here</a> for more on stan and this model in particular. To feed the <code>stan</code> model into <code>declaredesign</code> we use a handler to generate an analysis step that uses stan. The handler generates data in the form <code>stan</code> wants it in, runs the model, and extracts the quantities we care about.</li>
</ol>
<pre class="r"><code>f_bayesian = function(data) {
  J      &lt;- nrow(data)
  df     &lt;- list(J = J, y = data$est_effects, sigma = data$est_sds)
  fit    &lt;- stan(model_code = stan_model, data = df)
  fit_sm &lt;- summary(fit)$summary
  data.frame(estimate = fit_sm[,1][c(&quot;mu&quot;, &quot;tau&quot;, &quot;theta[1]&quot;, &quot;prob_pos&quot;)])}</code></pre>
<p>Here’s the full <code>stan</code> model that the handler calls on (based on <a href="https://github.com/stan-dev/rstan/wiki/RStan-Getting-Started">stan team’s code</a>, with an additional “generated quantities” block making predictions). The model details the type of data to be expected, the parameters,<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a> and the assumed data generation process (<code>model</code> block). Priors are not specified here so they are taken to be flat over their ranges. <code>stan</code> then seeks to calculate a posterior distribution on the priors given the data.</p>
<pre class="r"><code>stan_model &lt;- &quot; 
  data {
    int&lt;lower=0&gt; J;         // number of schools 
    real y[J];              // estimated treatment effects
    real&lt;lower=0&gt; sigma[J]; // standard error of effect estimates 
  }
  parameters {
    real mu;                // population treatment effect
    real&lt;lower=0&gt; tau;      // standard deviation in treatment effects
    vector[J] eta;          // unscaled deviation from mu by school
  }
  transformed parameters {
    vector[J] theta = mu + tau * eta;        // school treatment effects
  }
  model {
    target += normal_lpdf(eta | 0, 1);       // prior log-density
    target += normal_lpdf(y | theta, sigma); // log-likelihood
  }
 generated quantities {
    real&lt;lower=0&gt; prob_pos;                  // Probability an effect is &gt;0
    prob_pos =   1 - 1/(1+exp(-(0.07056 * (-mu/tau)^3 + 1.5976 * (-mu/tau))));   
  }
  &quot;</code></pre>
<p>With these estimators in hand, the design declaration is quite straightforward.</p>
<pre class="r"><code># Parameters
J     = 8   # Number of studies 
mu    = 1   # Assumed average effect
tau   = .5  # Heterogeneity of effects
sigma = .5  # Error in studies (assumed the same across studies), 
            # but could be a vector to reflect variation in precision across studies

# Design
metadesign &lt;- 
  declare_model(N = J, 
                true_effects = rnorm(N, mu, tau),
                est_effects = rnorm(N, true_effects, sigma),
                est_sds = sigma) +

  declare_inquiry(mu = mu, tau = tau, study_effect = true_effects[1], 
                  prob_pos  = 1 - pnorm(0, mu, tau))  +
  
  declare_estimator(handler = label_estimator(f_agnostic), label = &quot;Agnostic&quot;,
                    estimand = c(&quot;mu&quot;, &quot;tau&quot;, &quot;study_effect&quot;)) + 
  
  declare_estimator(handler = label_estimator(f_metaplus), label = &quot;Metaplus&quot;, 
                    estimand = c(&quot;mu&quot;, &quot;tau&quot;, &quot;prob_pos&quot;)) +
  
  declare_estimator(handler = label_estimator(f_bayesian), label = &quot;Bayesian&quot;,
                    estimand = c(&quot;mu&quot;, &quot;tau&quot;, &quot;study_effect&quot;, &quot;prob_pos&quot;))</code></pre>
<p>Let’s diagnose a set of designs of different sizes and plot some results.</p>
<pre class="r"><code>metadesigns &lt;- redesign(metadesign, J = c(4, 8, 16, 32))
diagnosis   &lt;- diagnose_design(metadesigns)</code></pre>
<p>Bias looks like this:</p>
<p><img src="/blog/2018-12-11-Meta-analysis_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<p>And the RMSE (expected error) looks like this:</p>
<p><img src="/blog/2018-12-11-Meta-analysis_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<p>We see that all approaches estimate the population average effect quite well. No bias and a RMSE that starts to vanish as <code>J</code> grows. They differ though in their estimates of variability and, because of this, in their predictions about the probability that the effect in a <em>next</em> study will be positive (<code>prob_pos</code>). They also differ in their final inferences about effects in the already completed studies (<code>study_effect</code>). In particular:</p>
<ul>
<li><p>The Bayesian model is biased here for <span class="math inline">\(\tau\)</span>—it ends up with too high an estimate of heterogeneity in expectation, since it starts with a very diffuse prior that it doesn’t let go of fast enough.<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a> In turn this means that the Bayesian model holds open the possibility of more negative effects arising from the population than we in fact would see given the model assumptions. The naive frequentist approach is also worse for <span class="math inline">\(\tau\)</span> and it doesn’t get much better with more studies.</p></li>
<li><p>The Bayesian model does <em>better</em> for <span class="math inline">\(\theta\)</span> than the other approaches. The reason is that the Bayesian model adjusts the individual study estimates based on inferences about the data generation.</p></li>
</ul>
<p>Having more studies wipes out the effects of priors, resulting in the Bayes model accurately estimating heterogeneity but still doing (even) better on <span class="math inline">\(\theta\)</span>.</p>
</div>
<div id="a-model-can-be-useful-even-when-its-wrong" class="section level1">
<h1>A model can be useful even when it’s wrong</h1>
<p>Both the Bayesian and metaplus approaches examined here to estimate <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\tau\)</span> make use of an assumption about the distribution of effects in a population. How robust are results to having the wrong model?</p>
<p>We explore a little by declaring a design in which effects are in fact distributed uniform over [0,2], rather than normally (so the mean is 1 and sd is (1/3)^.5) but the estimation erroneously supposes that effects are distributed normal. One big difference here is that although the variance in effects is a little larger there is now zero probability of a non positive effect. This new design requires changing both of the first two steps, though we will recycle steps 3 - 5:</p>
<pre class="r"><code>metadesign_2    &lt;- 
  
  declare_model(N = J, true_effects = runif(N, 0, 2),
                     est_effects = rnorm(N, true_effects, sigma), est_sds = sigma) +

  declare_inquiry(mu = mu, tau = .577, study_effect = true_effects[1], prob_pos  = 0)  +

  metadesign[[3]] + metadesign[[4]] + metadesign[[5]] </code></pre>
<table>
<thead>
<tr class="header">
<th align="left">Estimand Label</th>
<th align="left">Estimator Label</th>
<th align="left">Bias</th>
<th align="left">RMSE</th>
<th align="left">Mean Estimand</th>
<th align="left">Mean Estimate</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">mu</td>
<td align="left">Agnostic</td>
<td align="left">-0.01</td>
<td align="left">0.27</td>
<td align="left">1.00</td>
<td align="left">0.99</td>
</tr>
<tr class="even">
<td align="left">mu</td>
<td align="left">Bayesian</td>
<td align="left">-0.01</td>
<td align="left">0.28</td>
<td align="left">1.00</td>
<td align="left">0.99</td>
</tr>
<tr class="odd">
<td align="left">prob_pos</td>
<td align="left">Bayesian</td>
<td align="left">0.89</td>
<td align="left">0.90</td>
<td align="left">0.00</td>
<td align="left">0.89</td>
</tr>
<tr class="even">
<td align="left">study_effect</td>
<td align="left">Agnostic</td>
<td align="left">0.05</td>
<td align="left">0.51</td>
<td align="left">0.98</td>
<td align="left">1.03</td>
</tr>
<tr class="odd">
<td align="left">study_effect</td>
<td align="left">Bayesian</td>
<td align="left">0.04</td>
<td align="left">0.42</td>
<td align="left">0.98</td>
<td align="left">1.01</td>
</tr>
</tbody>
</table>
<p>We see the Bayesian approach continues to estimate study level effects better than the agnostic approach, despite having the wrong model. Though it does quite poorly on the out of sample predictions since it is working wiht the wrong distribution (and in particular one for which negative effects are always possible).</p>
<p>There are a few ways to improve upon this. Performance of the model can to some extent be assessed <em>within</em> the sample, e.g. by assessing how well a model developed on a subset of studies fares in predicting outcomes in another set of studies. Or more flexible approaches for modelling the underlying distribution of effects could be used (see e.g. <span class="citation">Beath (<a href="#ref-beath2014finite" role="doc-biblioref">2014</a>)</span>).</p>
<p>So models can help, even when wrong. But they can also lead you astray if too wrong.<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a> Hmm. If this all makes you nervous one option is to keep the focus on <span class="math inline">\(\mu\)</span> for which which is unbiased (though perhaps not very useful for out-of-sample predictions).</p>
</div>
<div id="if-we-dont-know-how-a-study-got-selected-into-a-sample-we-dont-have-strong-grounds-to-use-it-to-make-inferences-out-of-sample" class="section level1">
<h1>If we don’t know how a study got selected into a sample we don’t have strong grounds to use it to make inferences out of sample</h1>
<p>In practice in many (maybe all?) meta-analyses there is not a very good understanding of how individuals studies were selected from the population of studies of interest. This can make it hard to justify any kind of meta-analytic approach like these that strive to do more than estimate sample average effects. On the brighter side, if you have some information on how studies are selected then you can build that into the estimation <em>and</em> the design declaration and assess how sampling matters for inference.</p>
</div>
<div id="references." class="section level1 unnumbered">
<h1>References.</h1>
<div id="refs" class="references">
<div id="ref-beath2015metaplus">
<p>Beath, K, and B Bolker. 2015. “Metaplus: Robust Meta-Analysis and Meta-Regression.” <em>R Package Version 0.7-4</em>.</p>
</div>
<div id="ref-beath2014finite">
<p>Beath, Ken J. 2014. “A Finite Mixture Method for Outlier Detection and Robustness in Meta-Analysis.” <em>Research Synthesis Methods</em> 5 (4): 285–93.</p>
</div>
<div id="ref-gelman2013bayesian">
<p>Gelman, Andrew, Hal S Stern, John B Carlin, David B Dunson, Aki Vehtari, and Donald B Rubin. 2013. <em>Bayesian Data Analysis</em>. Chapman; Hall/CRC.</p>
</div>
<div id="ref-inthout2016plea">
<p>IntHout, Joanna, John PA Ioannidis, Maroeska M Rovers, and Jelle J Goeman. 2016. “Plea for Routinely Presenting Prediction Intervals in Meta-Analysis.” <em>BMJ Open</em> 6 (7): e010247.</p>
</div>
<div id="ref-kontopantelis2012performance">
<p>Kontopantelis, Evangelos, and David Reeves. 2012. “Performance of Statistical Methods for Meta-Analysis When True Study Effects Are Non-Normally Distributed: A Simulation Study.” <em>Statistical Methods in Medical Research</em> 21 (4): 409–26.</p>
</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>The parameters are (i) a real number, <span class="math inline">\(\mu\)</span>, (ii) a nonnegative real number <span class="math inline">\(\tau\)</span> and (iii) a set of <span class="math inline">\(J\)</span> unit level effects <span class="math inline">\(\theta_i\)</span> (to simplify computation the model defines deviations from the average effect as <span class="math inline">\(\eta_i\)</span> and then defines <span class="math inline">\(\theta_i\)</span> as <span class="math inline">\(\theta_i = \mu + \eta_i\tau\)</span>). <a href="#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p>You might find it discomforting to be applying such a frequentist ideas as bias to a Bayesian model; Bayesian models that get the prior right shouldn’t have any bias. The idea here though is that we assess ex ante what is the expected inference that will be made from a Bayesian approach given some data generating process that is not available to a researcher.<a href="#fnref2" class="footnote-back">↩︎</a></p></li>
<li id="fn3"><p>See <span class="citation">Kontopantelis and Reeves (<a href="#ref-kontopantelis2012performance" role="doc-biblioref">2012</a>)</span> for explorations.<a href="#fnref3" class="footnote-back">↩︎</a></p></li>
</ol>
</div>

        </div>
      </article>
      



    </div>
  </div>
</main>

    </div>

    

<footer>
    <div class="footer-top">
      <div class="container">
        <div class="row no-gutters">
          <div class="col-lg-7 col-md-12">
            <div class="row">
              <div class="col-md-3 col-12">
                <div class="footer-brand"><a href=""><img src="/images/brand-footer.svg" alt=""></a></div>
              </div>
              <div class="col-md-3 col-4">
                <p>DeclareDesign</p>
                <ul class="list-unstyled">
                  <li><a href="/">Home</a></li>
                  <li><a href="/about.html">About</a></li>
                  <li><a href="/r/designlibrary">Library</a></li>
                  <li><a href="/blog.html">Blog</a></li>
                  <li><a href="http://discuss.declaredesign.org/">Help</a></li>
                </ul>
              </div>
              <div class="col-md-3 col-4">
                <p>Software</p>
                <ul class="list-unstyled">
                  <li><a href="/r/declaredesign/">DeclareDesign</a></li>
                  <li><a href="/r/estimatr/">estimatr</a></li>
                  <li><a href="/r/randomizr/">randomizr</a></li>
                  <li><a href="/r/fabricatr/">fabricatr</a></li>
                  <li><a href="/r/designlibrary/">DesignLibrary</a></li>
                </ul>
              </div>
              
            </div>
          </div>
          <div class="col-lg-5 col-md-12"></div>
        </div>
      </div>
    </div>
    <div class="footer-bottom">
      <div class="footer-meta-block">
        <div class="container">
          <div class="row align-items-center">
            <div class="col-sm-7">
              <p class="mb-0">&copy; 2021 Graeme Blair, Jasper Cooper, Alexander Coppock, and Macartan Humphreys</p>
            </div>
            <div class="col-sm-5">
              <div class="fbl-link-wrap">
                <ul class="list-inline mb-0">
                  <li class="list-inline-item"> <a target="_blank" href="http://github.com/DeclareDesign/"><img src="images/icon-git.svg" alt=""></a> </li>
                </ul>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </footer>
  
   
  
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js" integrity="sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/js/bootstrap.min.js" integrity="sha384-ChfqqxuZUCnJSK3+MXmPNIyE6ZbWh2IMqE241rYiqJxyMiZ6OW/JmZQ5stwEULTy" crossorigin="anonymous"></script>

    <link rel="stylesheet" href="https://cdn.datatables.net/v/bs4/dt-1.10.18/datatables.min.css"/>
<script src="https://cdn.datatables.net/v/bs4/dt-1.10.18/datatables.min.js"></script>

<script>
    jQuery(function ()
    {
        const library_list = jQuery("#design_library_list");
        library_list.addClass("table table-striped table-bordered");
        library_list.DataTable(
            {
                "autoWidth": false,
                "columns":
                    [
                        {"width": "30%"}, 
                        {"width": "10%"}, 
                        {"width": "10%"}, 
                        {"width": "10%"}, 
                        {"width": "15%"}, 
                        {"width": "25%"}, 
                    ],
                "drawCallback": initialize_tooltips
            }
        );

        library_list.css("width", "");
    });

    function initialize_tooltips()
    {
        const tooltip_elements = jQuery('[data-toggle="tooltip"]');
        tooltip_elements.tooltip();
        tooltip_elements.click(function ()
        {
            jQuery(this).tooltip("hide");
        });
    }
</script>

    


<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>



<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/r.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/yaml.min.js"></script>
<script>
jQuery(function ()
{
  $('pre').each(function (index)
  {
    hljs.highlightBlock(this);
  });
});
</script>



    
<script src="/js/math-code.js"></script>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>


    



    
  </body>
</html>

