<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="generator" content="Hugo 0.79.0" />


  <title>Sometimes blocking can reduce your precision - DeclareDesign</title>




  









<link rel='stylesheet' href='https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css'>



<script defer src="https://use.fontawesome.com/releases/v5.5.0/js/all.js" integrity="sha384-GqVMZRt5Gn7tB9D9q7ONtcp4gtHIUEW/yG7h98J7IpE3kpi+srfFyyB/04OV6pG0" crossorigin="anonymous"></script>

<link href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,500,500i,700,700i" rel="stylesheet">

<link rel="stylesheet" href="/css/bootstrap.min.css">

<script src="https://code.jquery.com/jquery-3.3.1.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script>






  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Sometimes blocking can reduce your precision">
  <meta name="twitter:description" content='You can often improve the precision of your randomized controlled trial with blocking: first gather similar units together into groups, then run experiments inside each little group, then average results across experiments. Block random assignment (sometimes called stratified random assignment) can be great—increasing precision with blocking is like getting extra sample size for free. Blocking works because it’s like controlling for a pre-treatment covariate in the “Data Strategy” rather than in the “Answer Strategy.” But sometimes it does more harm than good.

'>






<script src="/js/dropdown_menu.js"></script>
<link rel="stylesheet" href="/css/custom.css">

  </head>
  <body>
    <div class="wrapper">
      
        
<header>
  <div class="navbar-wrap fixed-top bg-white">
    <nav class="navbar navbar-expand-lg navbar-light">
      <div class="container-fluid"> <a class="navbar-brand" href="/"><img src="/images/brand.svg" alt=""></a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"> <span class="navbar-toggler-icon"></span> </button>
        <div class="collapse navbar-collapse" id="navbarSupportedContent">
          <ul class="navbar-nav ml-auto">
            <li class="nav-item"><a class="nav-link" href="/getting-started.html">Getting Started</a></li>
            <li class="nav-item"><a class="nav-link" href="/r/designlibrary">Library</a></li>
            <li class="nav-item dropdown">
              
              <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown">Software <b class="caret"></b></a>
              <ul class="dropdown-menu">
                <li><a class="dropdown-item" href="/r/declaredesign/">DeclareDesign</a></li>
                <li><a class="dropdown-item" href="/r/randomizr/">randomizr</a></li>
                <li><a class="dropdown-item" href="/r/fabricatr/">fabricatr</a></li>
                <li><a class="dropdown-item" href="/r/estimatr/">estimatr</a></li>
                <li><a class="dropdown-item" href="/r/designlibrary/">DesignLibrary</a></li>
              </ul>
            </li>
            <li class="nav-item"><a class="nav-link" href="/blog.html">Blog</a></li>
            <li class="nav-item"><a class="nav-link" href="/about.html">About</a></li>
            <li class="nav-item"><a target="_blank" class="nav-link" href="http://discuss.declaredesign.org/">Help</a></li>
          </ul>
        </div>
      </div>
    </nav>
  </div>
</header>

 

      


<main class="container">
  <div class="row justify-content-between">
    <div class="col-lg-12" id="content_column">
      <article class="article">

        <a class="h1 d-block mb-3" href="/blog">DeclareDesign Blog</a>
        <h2 class="article-title">Sometimes blocking can reduce your precision</h2>

        
        <span class="article-date">2018/09/24</span>
        

        <div class="article-content">
          
<link href="/rmarkdown-libs/anchor-sections/anchor-sections.css" rel="stylesheet" />
<script src="/rmarkdown-libs/anchor-sections/anchor-sections.js"></script>


<p>You can often improve the precision of your randomized controlled trial with blocking: first gather similar units together into groups, then run experiments inside each little group, then average results across experiments. Block random assignment (sometimes called stratified random assignment) can be great—increasing precision with blocking is like getting extra sample size for free. Blocking works because it’s like controlling for a pre-treatment covariate in the “Data Strategy” rather than in the “Answer Strategy.” But sometimes it does more harm than good.</p>
<p>The standard experimental guidance is to block if you can in order to improve precision. (If for some reason you don’t have access to the pre-treatment covariates before the experiment is conducted, don’t fret, as the precision gains you would get from blocking on the front end can largely be made up by controlling on the back end.) In fact, even if you make blocks <em>at random</em>, you do as well as you would do under complete random assignment. For a textbook explanation of the benefits of blocking, see <span class="citation">Gerber and Green (2012)</span> (Section 3.6.1).</p>
<p>But is it possible to make things <em>worse</em>? Can you make a blocking that results in less precision than you would get from complete random assignment design?</p>
<p>The answer is yes. But you have to try really hard. If you organize units into groups that are internally unusually heterogeneous you can make things worse. For a formal analysis, see <span class="citation">Imai (2008)</span>.</p>
<div id="some-intuition" class="section level1">
<h1>Some intuition</h1>
<p>Why does blocking usually work? Under most circumstances, blocking works because it limits the <em>types</em> of assignment that might result from randomization Blocking works well when it rules out “bad” random assignments in favor of “good” random assignments.</p>
<p>For example, if you’ve got four units and you’re going to assign exactly two to treatment, there are <span class="math inline">\({4 \choose 2} = 6\)</span> possible ways to do it.</p>
<p>Imagine there is a covariate <span class="math inline">\(X = \{1, 2, 3, 4\}\)</span> that is correlated with potential outcomes. If we make matched pairs <span class="math inline">\(\{A, A, B, B\}\)</span>, we’ve done a “good” blocking and now there are only 4 possible assignments. We’ve ruled out the two “bad” assignments in which we only treat the first two units or only treat the last two units.</p>
<p>But if we make “bad blocks” <span class="math inline">\(\{A, B, B, A\}\)</span>, then we rule out the <strong>good</strong> assignments in which we treat units 1 and 4 or units 2 and 3 in favor of the <strong>bad</strong> assignments. It’s odd scenarios like these that can lead to precision decreases.</p>
</div>
<div id="bad-blocking-in-action" class="section level1">
<h1>Bad blocking in action</h1>
<p>Say your dataset includes information on romantic partners. You reason that couples tend to be similar on all sort of unobservables and so you decide to use the “couples” indicator as the blocking variable. Here’s a design:</p>
<pre class="r"><code>library(DeclareDesign)
library(tidyverse)

N = 100

population &lt;- declare_population(N = N, X = sort(rnorm(N)), u = rnorm(N))
potentials &lt;- declare_potential_outcomes(Y ~ Z - X * Z + u/10)
estimand   &lt;- declare_estimand(ATE = mean(Y_Z_1 - Y_Z_0))
blocking   &lt;- declare_step(fabricate, couples = rep(1:(N/2), each = 2))
assignment &lt;- declare_assignment(prob = .5, blocks = couples)
reveal     &lt;- declare_reveal(Y)
estimator  &lt;- declare_estimator(Y ~ Z)

design_likes &lt;-  population + potentials + estimand +
                 blocking + assignment + reveal + estimator</code></pre>
<p>The design here built in the assumption that couples are similar by putting people together if they have adjacent values of a prognostic (and, let’s assume, unobservable) variable, <span class="math inline">\(X\)</span>. In this design we have assumed an average effect of 1, but heterogeneity of effects that depends on <span class="math inline">\(X\)</span>.</p>
<p>But what if we are wrong about couples being similar? Let’s now assume that couples contain maximally <em>dissimilar</em> people. We’ll make a new design that differs from the last design by assuming a matching in which the lowest person on <span class="math inline">\(X\)</span> couples with the highest person on <span class="math inline">\(X\)</span>, the second lowest with the second highest, and so on.</p>
<pre class="r"><code>design_opposites &lt;-  replace_step(design_likes,
                                  blocking,
                                  declare_step(fabricate, couples = c(1:(N/2), (N/2):1)))</code></pre>
<p>We also want to compare both of these to a design with no blocking. To do this we will take <code>design_likes</code> and make a new design that just replaces the assignment step with one that does not use the blocks:</p>
<pre class="r"><code>design_no_blocks &lt;-  replace_step(design_likes,
                                  assignment,
                                  declare_assignment(prob = .5))</code></pre>
<p>We can simulate all three designs in one go and graph the distribution of estimated effects for each design—that is the distribution of estimated effects that you might get if you ran the experiment many times.</p>
<pre class="r"><code>simulate_design(design_likes, design_no_blocks, design_opposites) %&gt;%
  ggplot(aes(estimate)) +
    geom_histogram(bins = 30) +
    facet_wrap( ~ design_label) +
    theme_bw() +
    theme(strip.background = element_blank())</code></pre>
<p><img src="/blog/2018-09-24-bad_blocks_bad_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<p>The plots paint a pretty clear picture. All the distributions are centered on 1 (the true average effect), but they vary quite a bit in how dispersed they are—the more dispersed, the more off our answer is likely to be in any given experiment. If we make blocks out of couples that are similar to each other, the sampling distribution is super tight, meaning we have are more likely to be close to the right answer in any given experiment. But if we make blocks out of couples that are very different from each other, we actually do worse than in the no blocking case.</p>
<p>So blocking here will tend to work well if indeed couples are similar on dimensions that are correlated with potential outcomes. But the gains from blocking really depend on the assumption of couples being similar. If in fact “opposites attract,” then blocking on couple can do more harm than good.</p>
<p>We can confirm the graphical intuition by directly calculating the true standard error of each approach.</p>
<pre class="r"><code>diagnose_design(design_likes, design_no_blocks, design_opposites,
                diagnosands = declare_diagnosands(select = sd_estimate))</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">Design Label</th>
<th align="left">SD Estimate</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">design_likes</td>
<td align="left">0.103</td>
</tr>
<tr class="even">
<td align="left">design_no_blocks</td>
<td align="left">0.144</td>
</tr>
<tr class="odd">
<td align="left">design_opposites</td>
<td align="left">0.173</td>
</tr>
</tbody>
</table>
<p>So there you have it. It is technically possible that some blocking strategies could make things worse. If you make homogeneous blocks (homogeneous in terms of potential outcomes), blocking helps. But if you make <em>heterogeneous</em> blocks (again in terms of potential outcomes) blocking could hurt.</p>
</div>
<div id="size" class="section level1">
<h1>Size</h1>
<p>As discussed in <span class="citation">Moore (2012)</span> and <span class="citation">Imai, King, and Stuart (2008)</span>, “bad blocking” is often only a problem in small samples and can go away if the sample size is sufficiently large.</p>
<p>How small small is will depend on the background model and specifics of the estimand <span class="citation">(Imai 2008)</span>. For any given model, however, <code>DeclareDesign</code> makes it easy to answer that kind of question. Here we do the same diagnosis as above but with larger designs with <span class="math inline">\(N\)</span>s of 250 and 2500.</p>
<pre class="r"><code>diagnose_design(Like_blocks_250  = redesign(design_likes,     N = 250),
                No_blocks_250    = redesign(design_no_blocks, N = 250),
                Opposites_250    = redesign(design_opposites, N = 250),
                Like_blocks_2500 = redesign(design_likes,     N = 2500),
                No_blocks_2500   = redesign(design_no_blocks, N = 2500),
                Opposites_2500   = redesign(design_opposites, N = 2500),
                diagnosands      = declare_diagnosands(select = sd_estimate))</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">Design Label</th>
<th align="right">N</th>
<th align="left">SD Estimate</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Like_blocks_250</td>
<td align="right">250</td>
<td align="left">0.064</td>
</tr>
<tr class="even">
<td align="left">No_blocks_250</td>
<td align="right">250</td>
<td align="left">0.090</td>
</tr>
<tr class="odd">
<td align="left">Opposites_250</td>
<td align="right">250</td>
<td align="left">0.110</td>
</tr>
<tr class="even">
<td align="left">Like_blocks_2500</td>
<td align="right">2500</td>
<td align="left">0.020</td>
</tr>
<tr class="odd">
<td align="left">No_blocks_2500</td>
<td align="right">2500</td>
<td align="left">0.028</td>
</tr>
<tr class="even">
<td align="left">Opposites_2500</td>
<td align="right">2500</td>
<td align="left">0.035</td>
</tr>
</tbody>
</table>
<p>We see here how the loss from bad blocking declines, in absolute terms, with sample size (as does variance in general). In <em>relative</em> terms though we note that we are not seeing clear declines for this design. In the <span class="math inline">\(N = 100\)</span> case the variance in the sampling distribution with bad blocking is an estimated 45% bigger than the variance with no blocking; for <span class="math inline">\(N = 250\)</span> it is 50% bigger and for <span class="math inline">\(N = 2500\)</span> it is 52% bigger.</p>
<div id="references" class="section level2 unnumbered">
<h2>References</h2>
<div id="refs" class="references">
<div id="ref-gerber2012field">
<p>Gerber, Alan S., and Donald P. Green. 2012. <em>Field Experiments: Design, Analysis, and Interpretation</em>. WW Norton.</p>
</div>
<div id="ref-imai2008variance">
<p>Imai, Kosuke. 2008. “Variance Identification and Efficiency Analysis in Randomized Experiments Under the Matched-Pair Design.” <em>Statistics in Medicine</em> 27 (24): 4857–73.</p>
</div>
<div id="ref-imai2008misunderstandings">
<p>Imai, Kosuke, Gary King, and Elizabeth A Stuart. 2008. “Misunderstandings Between Experimentalists and Observationalists About Causal Inference.” <em>Journal of the Royal Statistical Society: Series A (Statistics in Society)</em> 171 (2): 481–502.</p>
</div>
<div id="ref-moore2012multivariate">
<p>Moore, Ryan T. 2012. “Multivariate Continuous Blocking to Improve Political Science Experiments.” <em>Political Analysis</em> 20 (4): 460–79.</p>
</div>
</div>
</div>
</div>

        </div>
      </article>
      



    </div>
  </div>
</main>

    </div>

    

<footer>
    <div class="footer-top">
      <div class="container">
        <div class="row no-gutters">
          <div class="col-lg-7 col-md-12">
            <div class="row">
              <div class="col-md-3 col-12">
                <div class="footer-brand"><a href=""><img src="/images/brand-footer.svg" alt=""></a></div>
              </div>
              <div class="col-md-3 col-4">
                <p>DeclareDesign</p>
                <ul class="list-unstyled">
                  <li><a href="/">Home</a></li>
                  <li><a href="/about.html">About</a></li>
                  <li><a href="/r/designlibrary">Library</a></li>
                  <li><a href="/blog.html">Blog</a></li>
                  <li><a href="http://discuss.declaredesign.org/">Help</a></li>
                </ul>
              </div>
              <div class="col-md-3 col-4">
                <p>Software</p>
                <ul class="list-unstyled">
                  <li><a href="/r/declaredesign/">DeclareDesign</a></li>
                  <li><a href="/r/estimatr/">estimatr</a></li>
                  <li><a href="/r/randomizr/">randomizr</a></li>
                  <li><a href="/r/fabricatr/">fabricatr</a></li>
                  <li><a href="/r/designlibrary/">DesignLibrary</a></li>
                </ul>
              </div>
              
            </div>
          </div>
          <div class="col-lg-5 col-md-12"></div>
        </div>
      </div>
    </div>
    <div class="footer-bottom">
      <div class="footer-meta-block">
        <div class="container">
          <div class="row align-items-center">
            <div class="col-sm-7">
              <p class="mb-0">&copy; 2021 Graeme Blair, Jasper Cooper, Alexander Coppock, and Macartan Humphreys</p>
            </div>
            <div class="col-sm-5">
              <div class="fbl-link-wrap">
                <ul class="list-inline mb-0">
                  <li class="list-inline-item"> <a target="_blank" href="http://github.com/DeclareDesign/"><img src="images/icon-git.svg" alt=""></a> </li>
                </ul>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </footer>
  
   
  
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js" integrity="sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/js/bootstrap.min.js" integrity="sha384-ChfqqxuZUCnJSK3+MXmPNIyE6ZbWh2IMqE241rYiqJxyMiZ6OW/JmZQ5stwEULTy" crossorigin="anonymous"></script>

    <link rel="stylesheet" href="https://cdn.datatables.net/v/bs4/dt-1.10.18/datatables.min.css"/>
<script src="https://cdn.datatables.net/v/bs4/dt-1.10.18/datatables.min.js"></script>

<script>
    jQuery(function ()
    {
        const library_list = jQuery("#design_library_list");
        library_list.addClass("table table-striped table-bordered");
        library_list.DataTable(
            {
                "autoWidth": false,
                "columns":
                    [
                        {"width": "30%"}, 
                        {"width": "10%"}, 
                        {"width": "10%"}, 
                        {"width": "10%"}, 
                        {"width": "15%"}, 
                        {"width": "25%"}, 
                    ],
                "drawCallback": initialize_tooltips
            }
        );

        library_list.css("width", "");
    });

    function initialize_tooltips()
    {
        const tooltip_elements = jQuery('[data-toggle="tooltip"]');
        tooltip_elements.tooltip();
        tooltip_elements.click(function ()
        {
            jQuery(this).tooltip("hide");
        });
    }
</script>

    


<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>



<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/r.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/yaml.min.js"></script>
<script>
jQuery(function ()
{
  $('pre').each(function (index)
  {
    hljs.highlightBlock(this);
  });
});
</script>



    
<script src="/js/math-code.js"></script>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>


    



    
  </body>
</html>

